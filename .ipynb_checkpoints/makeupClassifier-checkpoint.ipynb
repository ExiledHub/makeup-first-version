{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "<p>\n",
    "Numpy: Math related stuff but mainly for linear algebra.\n",
    "</p>\n",
    "<p>\n",
    "Pandas: Importing and processing data.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e02457f3ab89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "from pathlib import Path\n",
    "import imageio\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, datasets\n",
    "\n",
    "import random\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "random.seed(69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Organization\n",
    "Now that we have defined our imports, lets go ahead and get our data imported and organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw images from the Makeup collection and sort them checking they are unique.\n",
    "raw_images = Path('/kaggle/input/make-up-vs-no-make-up/data/data/makeup').glob('*.jpeg')\n",
    "sorted_images_makeup = sorted([ image for image in raw_images])\n",
    "\n",
    "standard_width = 128\n",
    "standard_height = 128\n",
    "image_channels = 3\n",
    "training_data = np.empty([None,150,150,3])\n",
    "\n",
    "# Path stores the relative path to the image while the makeup stores a boolean.\n",
    "# Think about it as the input and the output of the CNN.\n",
    "for path in sorted_images_makeup:\n",
    "    image = Image.open(str(path))\n",
    "    image = image.resize((150,150))\n",
    "    data.append\n",
    "    data.append([image,150,150,3, \"True\"])\n",
    "\n",
    "# Get raw images from the No Makeup collection and sort them checking they are unique.\n",
    "raw_images = Path('/kaggle/input/make-up-vs-no-make-up/data/data/no_makeup').glob('*.jpeg')\n",
    "sorted_images_noMakeup = sorted([ image for image in raw_images])\n",
    "\n",
    "# Path stores the relative path to the image while the makeup stores a boolean.\n",
    "# Think about it as the input and the output of the CNN.\n",
    "for path in sorted_images_makeup:\n",
    "    image = Image.open(str(path))\n",
    "    image = image.resize((150,150))\n",
    "    data.append([image,150,150,3, \"False\"])\n",
    "\n",
    "random.shuffle(data)\n",
    "    \n",
    "dataframe = pd.DataFrame(data, columns = ['Image', 'Width', 'Height', 'Channels', 'Makeup'])\n",
    "\n",
    "print(dataframe)\n",
    "\n",
    "#print('We are going to analyse',len(sorted_images),\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Early Image Visualization\n",
    "![](http://)Now that we have all the paths for our images and lables for each one of them, we can check using matplotlib by ploting the images in real-time. Lets check #69 because why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = dataframe.at[69, 'Image']\n",
    "plt.imshow(image)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ConvNet\n",
    "The Convolutional Neural Network will take an image as an input and return us if it has make-up or not. We have data in this moment made out of images and lables, so the input and the output of the network. We now need trainging and test data out of this data. For this, we need to randomly select makeup and no-makeup images for both collections. Also, normalization in this case is not absolutly needed, but we will apply it anyways just to make sure we don't have exploding gradients later.\n",
    "\n",
    "Our architecture will consist of a Conv (2x2) + ReLu, then a Conv (4x4) + ReLu and finally a max pooling layer. We will repeat that 5 times, then we will flatten the result and feed it into 5 fully connected layers, ending on a Softmax. This means 7 Artificial Layers including the result layer. \n",
    "\n",
    "We have a total of 2124 images, we are going to use 500 for testing and 1624 for training. Lets start by getting that organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels) = (dataframe[:len(data)-500][['Image','Width','Height','Channels']].values,dataframe[:len(data)-500]['Makeup'].values)\n",
    "(test_images, test_labels) = (dataframe[len(data)-500:][['Image','Width','Height','Channels']].values,dataframe[len(data)-500:]['Makeup'].values)\n",
    "\n",
    "print(train_images.reshape(len(data)-500,1,1,1))\n",
    "print(train_images[1].size)\n",
    "print(train_images[2].size)\n",
    "print(train_images[3].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 128\n",
    "image_height = 128\n",
    "image_channels = 3\n",
    "\n",
    "#1 conv\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (2,2), padding=\"same\", activation='relu', input_shape=(image_width,image_height,image_channels)))\n",
    "model.add(layers.Conv2D(32, (4,4), padding=\"same\", activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "#2 conv\n",
    "model.add(layers.Conv2D(32, (2,2), padding=\"same\", activation='relu'))\n",
    "model.add(layers.Conv2D(64, (4,4), padding=\"same\", activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "#3 conv\n",
    "model.add(layers.Conv2D(64, (2,2), padding=\"same\", activation='relu'))\n",
    "model.add(layers.Conv2D(128, (4,4), padding=\"same\", activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "#4 conv\n",
    "model.add(layers.Conv2D(128, (2,2), padding=\"same\", activation='relu'))\n",
    "model.add(layers.Conv2D(256, (4,4), padding=\"same\", activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "#5 conv\n",
    "model.add(layers.Conv2D(256, (2,2), padding=\"same\", activation='relu'))\n",
    "model.add(layers.Conv2D(512, (4,4), padding=\"same\", activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# Flatten\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "#1 dense\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "#2 dense\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "#3 dense\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "#4 dense\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "#5 dense\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Softmax\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training\n",
    "Now that we have build a model and organized the data into a nice randomized batched, lets get started with training the beast! We need to define a few things first, like what type of optimizer we are going to use and the loss function. We are going to use Adam optimization and crossvalidation in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
